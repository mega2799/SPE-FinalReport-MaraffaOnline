
\chapter{DevOps}
\label{ch:DevOps} % Label for method chapter
\section{Semantic Versioning, changelog e secrets}
\subsection{Semantic Versioning}
Per ogni release è stato adottato il semanting Versioning. È stato utilizzato il formato X.Y.Z, partendo da 1.0.0, ogni release incrementa il numero di versione in base a:
\begin{itemize}
    \item \textbf{Major (X):} per cambiamenti incompatibili con le versioni precedenti
    \item \textbf{Minor (Y):} per aggiunta di nuove funzionalità compatibili con le versioni precedenti
    \item \textbf{Patch (Z):} per correzione di bug compatibili con le versioni precedenti
\end{itemize}
Per ogni release viene creato anche un tag con la corrispondente versione.
\subsection{Changelog e secrets}
Ogni volta che is effettua una push sul main, viene generato un changelog. Il changelog è un file che contiene tutte le modifiche effettuate.
Nel changelog vengono riportati ogni commit che indicano le modifiche apportate, i contributori e il codice sorgente.
Se presenti, vengono inoltre riportate le sezioni: 
\begin{itemize}
    \item \textbf{feat: Feature} per le nuove funzionalità
    \item \textbf{fix: Bug Fixes} per le correzioni di bug
    \item \textbf{docs: Documentation} per le modifiche alla documentazione
    \item \textbf{refactor: Refactor} per le modifiche al codice che non aggiungono nuove funzionalità
    \item \textbf{perf: Performance Improvements} per le modifiche che migliorano le prestazioni
    \item \textbf{CI: Continuos Integration} per le modifiche alla CI
\end{itemize}
Il changelog viene autogenerato tramite l'action 'BobAnkh/auto-generate-changelog@v1.2.5'.
Inoltre per evitare un accesso non autorizzato a dati sensibili, come l'access token del changelog, sono stati inseriti in secrets, variabili d'ambiente di Github. 
\section{Licensing e issue template}
In ogni nostra repo è presente una licenza MIT. È stata scelta questa licenza perché è estremamente permissiva: 
il codice sorgente di Maraffa Online è open source e pertanto gli utenti possono utilizzarlo, modificarlo e distribuirlo.
Inoltre la licenza MIT è compatibile anche con altre licenze, anche con quelle restrittive come GPL.
È incoraggiata la collaborazione anche grazie alla presenza di un template con il quale un utente può consigliare nuove feature,
 segnalare un bug o suggerire un'implementazione alternativa.
\section{DVCS}

Come strumento di controllo di versione è stato scelto git, sono state adottate le seguenti best practices o git policy per garantire un flusso di lavoro coerente e prevenire conflitti di merge.
% La Git Policy rappresenta un insieme di linee guida e regole che governano l'uso di Git all'interno di un team di sviluppo. 
% Queste politiche sono fondamentali per garantire un flusso di lavoro coerente, prevenire conflitti di merge e mantenere una storia del codice chiara e facilmente navigabile. 

\subsection{Struttura dei Branch}

Una delle componenti principali della Git Policy è la gestione dei branch. La struttura tipica prevede almeno tre tipi di branch:
\begin{itemize}
 \item \textbf{Master/Main:} Questo è il branch principale che contiene il codice di produzione. Ogni commit su questo branch dovrebbe essere stabile e pronto per il rilascio. Questo branch e stato protetto per evitare commit diretti, richiedendo quindi una revisione per ogni operazione di merge.
 \item \textbf{Develop:} Qui viene integrato il lavoro di sviluppo corrente. È il branch dove confluiscono le feature prima di essere preparate per il rilascio. Questo branch dovrebbe essere costantemente aggiornato e testato per assicurare che sia in uno stato pronto per la produzione.
 \item \textbf{Feature Branches:} Utilizzati per lo sviluppo di nuove funzionalità. Ogni feature branch deve derivare da `develop` e, una volta completata la feature, viene reintegrato in `develop` tramite una pull request.
\end{itemize}


% \subsection{Commit e Messaggi di Commit}

% La pratica adottata per i commit è stata quella di effettuare commit frequenti e significativi.
% Per facilitare la comprensione di ogni commit si è adotatto lo standard : \href{https://www.conventionalcommits.org/en/v1.0.0/}{Conventional Commits}, che divide i commit in categorie come `fix`, `feat`, `docs`, `style`, `refactor`, `test`, `chore`, `ci`, `perf`, `build`, `revert`. 
\subsection{Struttura delle repository}

Data la natura del sistema, sono state necessarie numerose repository Git per evitare confusione, separare correttamente i componenti e poterli rilasciare indipendentemente.
Il sistema, tuttavia, è comunque utilizzabile e rintracciabile attraverso la repository GitLab di ateneo PikaLab, poiché è stata implementata una repository con submodules che le contiene. 
Inoltre, in questa repository si può trovare il docker-compose per il deploy del sistema completo e sempre aggiornato, assieme ad alcuni file statici per il suo funzionamento e configurazione.

\subsection{Pull Request e Code Review}

Le pull request (PR) sono essenziali per garantire la qualità del codice. Ogni PR è stata sottoposta a una code review da parte di uno o più membri del team. 
Questo processo non solo aiuta a individuare errori e problemi di design, ma promuove anche la condivisione delle conoscenze e facilita, tramite la 
comparazione di codice, la spiegazione di nuove funzionalità introdotte entro la fine dello sprint.


\subsection{Gestione dei Conflitti}

I conflitti di merge sono inevitabili in un ambiente di sviluppo collaborativo soprattutto quando è difficile modulare le parti di un SW.
% La gestione di confilitti, è stata gestita preferendo la risoluzione locale, in modo da evitare conflitti complessi e blocchi nel flusso di lavoro.
La scelta tra merge e rebase è stata fatta in base al contesto e alla complessità delle modifiche, privilegiando la chiarezza della storia del codice seppur a discapito della linearità, 
quindi di utilizzare il merge per mantenere una storia del codice più pulita e continua.
Questo è particolarmente utile per tracciare
l’evoluzione del progetto e per individuare facilmente l’origine dei bug. 
Infatti con il rebase c'è il rischio che venga cancellata una parte della history. In alcuni casi, può risultare molto pericoloso e 
può introdurre rischi significativi se non utilizzato con estrema cautela:
ipotizzando di introdurre un bug e successivamente di eseguire il rebase che cancella dalla history la modifica che ha introdotto il bug,
risulterebbe particolarmente ostico tracciare le modifiche e risalire a questo cambiamento. Potenzialmente può creare anche confusione tra i membri del team.
Per lo stesso motivo, non è mati stato utilizzato il merge con squash commit che di fatto avrebbe modificato la cronologia dei commit e reso difficile tracciare le modifiche originarie.

% Infatti, il merge evita 
% di riscrivere la cronologia dei commit, il che può causare problemi se altri sviluppatori hanno 
% basato il loro lavoro sui commit riscritti.  il rebase può introdurre rischi significativi se non utilizzato con estrema cautela
% in quanto riscrive la cronologia, rendendo difficile tracciare le modifiche originarie e potenzialmente causando confusione tra i membri del team.

% \subsection{Gestione dei conflitti in Git e scelta della tattica di merge}

% La gestione dei conflitti in Git è una parte fondamentale del flusso di lavoro collaborativo. I conflitti si verificano quando due o più branch presentano modifiche incompatibili agli stessi file o alle stesse righe di codice. Per risolvere questi conflitti, Git offre due principali tattiche: merge e rebase.

% Il merge è generalmente preferito al rebase in molti contesti di team per diversi motivi. Innanzitutto, il merge preserva la cronologia completa del progetto, mantenendo un registro di tutte le modifiche e delle fusioni effettuate. Questo è particolarmente utile per tracciare l'evoluzione del progetto e per individuare facilmente l'origine dei bug. Inoltre, il merge evita di riscrivere la cronologia dei commit, il che può causare problemi se altri sviluppatori hanno basato il loro lavoro sui commit riscritti. 

% Il rebase, sebbene utile per mantenere una cronologia lineare e pulita, può complicare la risoluzione dei conflitti in quanto riscrive la cronologia, rendendo difficile tracciare le modifiche originarie e potenzialmente causando confusione tra i membri del team. In ambienti collaborativi, il rebase può introdurre rischi significativi se non utilizzato con estrema cautela.

% In sintesi, mentre il rebase può essere utile in specifiche situazioni, il merge è solitamente preferito per la sua capacità di mantenere una cronologia trasparente e di evitare i problemi associati alla riscrittura della cronologia dei commit.


\subsection{Strumenti di Supporto TODO questo utile potrebbe essere spostato in un'altra sezione}

Per implementare efficacemente queste best practices, è utile utilizzare strumenti di supporto come:
- \textbf{Git Hooks:} Script che vengono eseguiti automaticamente in determinati punti del flusso di lavoro di Git, come prima di un commit o dopo un merge. Possono essere utilizzati per verificare la qualità del codice, eseguire test automatizzati, o applicare formattazioni standard.
- \textbf{Linting e Formattazione Automatizzata:} Utilizza strumenti come ESLint o Prettier per mantenere uno stile di codice coerente e rilevare potenziali errori prima che vengano committati.
- \textbf{Monitoraggio e Analisi:} Strumenti come SonarQube possono analizzare il codice per trovare problemi di sicurezza, bug, e debito tecnico.

% \subsection{Strategy for version control}
% **parla della git policy**
% \subsection{Git workflow}
% **main, develop, feature branch...***
\subsection{Commit verification}
È stato utilizzato il meccanismo di commit verification per assicurare:
\begin{itemize}
    \item \textbf{Integrità:} controllo sull'alterazione dei file presenti all'interno del commit.  Utilizzando una funzione hash, ci si assicura che non siano stati alterati in non modo autorizzato.
    \item \textbf{Autenticità:} controllo sull'autore del commit. Utilizzando una firma digitale, ci si assicura che il commit sia stato effettuato dall'autore autorizzato.
\end{itemize}
I controlli vengono effettuati in seguito a un merge. \\
Quando un commit è verificato viene prodotto un tag verde con la scritta "verified" e un tag rosso con la scritta "unverified" in caso contrario:
\begin{figure}[h!]
    \centering 
    \includegraphics[scale=0.7]{report/img/verified_commit.png}
    \caption{Verified commit}
    \label{verified_commit}
    \end{figure}
\subsection{Conventional commits}
La pratica adottata per i commit è stata quella di effettuare commit frequenti e significativi.

In ogni repo è stato adottato un sistema standard per scrivere i commit:  i conventional commit. In questo modo i commit risultano più chiari e facilmente leggibili. 
Riportiamo di seguito la nomenclatura usata:
\begin{itemize}
    \item \textbf{fix:} per i commit che risolvono un bug
    \item \textbf{feat:} per i commit che aggiungono una nuova feature
    \item \textbf{refactor:} per i commit che migliorano il codice senza aggiungere nuove funzionalità
    \item \textbf{docs:} per i commit che riguardano la documentazione
    \item \textbf{style:} per i commit che riguardano la formattazione del codice
    \item \textbf{test:} per i commit che riguardano i test
    \item \textbf{ci:} per i commit che riguardano la Continuous Integration
\end{itemize}
Inoltre sono evidenziati i breaking changes per le modifiche non più compatibili con le versioni precedenti.
La stessa nomenclatura viene utilizzata anche nel changelog.


\section{Build automation}
Abbiamo deciso di implementare ogni servizio in una repository diversa. La repository fornita è un contenitore di tutte le singole repository dei servizi.
Per ogni repository è stata implementata una build automation specifica. \\
In questo modo si riesce a automatizzare i processi di build, test e deploy, ottenendo diversi vantaggi:
\begin{itemize}
    \item si riduce drasticamente il tempo per la compilazione del codice
    \item ogni volta i passaggi verranno eseguiti allo stesso modo ottenendo, quindi, riproducibilità
    \item si identificano facilmente i problemi grazie al sistema di stampe a video che si ottiene durante l'esecuzione delle GitHub Actions
    \item minimizzazione degli errori umani
    \item garantisce il continuous deployment 
\end{itemize}


\subsection{UserManagementMaraffa e BusinessLogic:} Essendo le due repository estremamente simili e avendo entrambe un ambiente in node.js, è stato implementato un workflow pressochè analogo.
 Questo workflow reagisce all'evento di pull request chiuse sul branch develop e alle release, le quali vengano generate a mano. Durante lo sviluppo del workflow, infatti, si 
 è notato come non fosse possibile catturare l'evento della creazione di un nuovo tag che avrebbe permesso di automatizzare 
 il processo di release di github.
e sono stati implementati 3 job: build, test e deploy.
Dopo una checkout iniziale,
 viene creata una cache per permettere ai job di comunicare tra loro. Successivamente alla build il sistema viene testato
  (in entrambi i casi viene usata l'action di yarn) e infine viene effettuato il deploy del servizio containerizzato
 Nel quale viene effettuato il chekout, si configura il nome del progetto e si configura la versione della build.
 Se il commit viene effettuato sul main si configura il nome del tag e la versione a "LATEST", nel caso non fosse nel main viene configurata la versione a "develop".
  Infine si effettua il login al Github container registry, la build e la push dell'immagine sul registro. L'immagine viene configurata in modo parametrico con delle variabili d'ambiente e il nome viene trasformato in minuscolo. 

\subsection{MiddlewareMaraffa:} 
Quando viene effettuata una release o una pull request sul branch develop ed è di tipo closed
(non sta progredendo e quindi l’esecuzione non è in corso) il workflow del Middleware viene attivato.
Anch'esso è costituito da tre jobs: build, test e deploy.
Come prima cosa nella build, viene eseguito il checkout, effettuato il setup di Java e Gradle. Infine viene effettuata la 
build di Gradle.
Nel job del test si crea un container con un database di MongoDB. Password e username vengono passati tramite i secrets. Successivamente
si prosegue con checkout, setup di Java utilizzando la cache per utilizzare la build di Gradle svolta precedentemente e 
infine si esegue il test con gradlew.
Per quanto riguarda il deploy, si effettua il checkout utilizzando un token salvato all'interno di un secret. La parte
restante coincide con quella delle repository precedenti.
% push su main, pull request su main e develop
% build e test se pullrequest.merge = true 

% Parte finale 


\subsection{FrontendMaraffa:} TODO
Sarebbe figo spiegare come i nostri workflow hanno ridotto i conflitti di integrazione, il rilevamento precoce di bug e i problemi di compatibilità.


\section{Continuous Integration}
Per migliorare la qualità del software e velocizzare il processo di sviluppo, è stata implementata la Continuous Integration.
Questa pratica permette di integrare il codice frequentemente, evitando possibili rischi d'integrazione e consetendo 
l'esecuzione di test automatici. Grazie al sistema di notifiche, inoltre, è possibile ricevere feedback immediato sullo stato delle Github Actions,
per accertarsi che sia sempre tutto funzionante e non siano stati introdotti bug. Mantenendo il sistema continuamente monitorato,
si migliora anche l'effiicienza e la collaborazione tra i membri del team.

\section{Automated quality assurance}
\subsection{Testing}

Per ogni servizio in questo sistema è stato adottato, ove possibile, il paradigma di programmazione TDD, cioè Test Driven Development. Questo approccio prevede che i test siano scritti prima del codice, in modo da guidare lo sviluppo e garantire che il codice prodotto soddisfi i requisiti specificati.
All'interno della CI, la fase di test è stata implementata con Jest per quanto riguarda i servizi che usano Node.js, generando di fatto un report abbastanza comprensibile direttamente nella finestra della CI. Il componente middleware, scritto in Java, invece, generava risultati di test non così chiari. Per modificare questo comportamento, è stata introdotta una dipendenza nel build Gradle che permette di avere un report più dettagliato e comprensibile. 
La libreria \href{https://plugins.gradle.org/plugin/com.adarshr.test-logger}{\underline{Test Logger}}, tramite una piccola configurazione nel file build.gradle come qui riportata, ha soddisfatto le nostre esigenze.

\begin{lstlisting}[language=Java, caption={Test logger}, label=list:gradle_testlogger]
import com.adarshr.gradle.testlogger.TestLoggerExtension
import com.adarshr.gradle.testlogger.TestLoggerPlugin
import com.adarshr.gradle.testlogger.theme.ThemeType

testlogger {
    theme = ThemeType.MOCHA
    showExceptions = true
    showStackTraces = true
    showFullStackTraces = false
    showCauses = true
    slowThreshold = 2000
    showSummary = true
    showSimpleNames = false
    showPassed = true
    showSkipped = true
    showFailed = true
    showOnlySlow = false
    showStandardStreams = false
    showPassedStandardStreams = true
    showSkippedStandardStreams = true
    showFailedStandardStreams = true
    logLevel = LogLevel.LIFECYCLE
}
\end{lstlisting}

\subsection{Act per testare CI}

È stato trovato un utilissimo strumento per poter velocizzare il processo di creazione della CI, \href{https://github.com/nektos/act}{\underline{Act}}. Questo strumento permette di eseguire le GitHub Actions localmente senza dover obbligatoriamente fare un push sul repository e quindi senza "sporcare" la cronologia dei commit. Richiede che Docker sia attivo ed è in grado di creare un container che utilizza l'immagine specificata nel file di configurazione della CI e di eseguire i job. Per eseguire Act è stato creato uno script in bash per poter automatizzare ulteriormente il testing delle CI, in cui viene letto il contenuto del file .env.example che popolerà l'environment del container con le variabili d'ambiente necessarie per il corretto funzionamento della CI, e le imposta come variabili d'ambiente della GitHub Action che si sta testando. Per poter usare Act è necessario semplificare leggermente il trigger per i job, che in ambiente di produzione è solitamente la chiusura di una pull request, mentre per testare velocemente è necessario impostarlo su una push.

\section{Code quality e linting} 
\label{code_quality}

Durante lo sviluppo dei servizi è stata adottata una politica di code quality e linting per garantire la coerenza e la leggibilità del codice.

\vspace{0.5cm}

Per i servizi in Node.js, sono stati utilizzati ESLint assieme a Prettier. ESLint è uno strumento di analisi statica del codice che aiuta a identificare e correggere gli errori di codice, le pratiche non ottimali e le violazioni dello stile di codice.
Questi strumenti necessitano soltanto di un file di configurazione che è presente nelle repository e che i software per la scrittura di codice, come ad esempio VSCode, possono adoperare.

\vspace{0.5cm}

Il componente in Java ha adottato Checkstyle, un tool di analisi statica del codice che aiuta a garantire che il codice Java rispetti uno standard di codifica predefinito. Anche in questo caso è stato sufficiente aggiungere una dipendenza nel build.gradle per ottenere un report dettagliato e comprensibile ed un file di configurazione che è stato inserito nella repository. Per automatizzare il processo di formattazione del codice il più possibile è stata aggiunta la libreria \href{https://github.com/diffplug/spotless}{\underline{Spotless}}. L'aggiunta di queste dipendenze nel file build.gradle è stata sufficiente per garantire la formattazione del codice e la sua coerenza.

\begin{lstlisting}[language=Java, caption={Code quality}, label=list:gradle_codequality]
spotless {
    java {
        importOrder() // standard import order
        removeUnusedImports()
        googleJavaFormat() // has its own section below
        eclipse()          // has its own section below
    }
}
checkstyle {
    toolVersion = "8.44" // Versione di Checkstyle
    configFile = file("${rootDir}/config/checkstyle/checkstyle.xml") // Configurazione di Checkstyle
    // showViolations = true
}
\end{lstlisting}


\subsection{Checkstyle, javadoc, github page }

% Il componente middleware è stato sviluppato in Java e per garantire la qualità del codice sono stati utilizzati strumenti come Checkstyle e Spotless, come citato in \ref{code_quality}. 
Dopo aver eseguito i controlli di stile sul codice sono stati trovati numerosi errori e warning, che sono stati corretti automaticamente da un plugin che ha sistemato ciò che Spotless non era riuscito a correggere. Il plugin in questione è \href{https://github.com/openrewrite/rewrite}{\underline{OpenRewrite}}, che ha permesso di correggere molti errori e di risparmiare un lungo e noioso lavoro di correzione manuale.

\begin{lstlisting}[language=Bash, caption={Output di OpenRewrite}, label=list:openrewrite]
Changes have been made to app\src\main\java\userModule\UserController.java by:
    org.openrewrite.staticanalysis.CodeCleanup
        org.openrewrite.java.format.MethodParamPad
Changes have been made to app\src\main\java\userModule\UserService.java by:
    org.openrewrite.staticanalysis.CodeCleanup
        org.openrewrite.staticanalysis.NeedBraces
Changes have been made to app\src\test\java\integration\BusinessLogicTestIntegration.java by:
    org.openrewrite.staticanalysis.CodeCleanup
        org.openrewrite.java.format.MethodParamPad
Please review and commit the results.
Estimate time saved: 1h 24m 
\end{lstlisting}

Dopo aver corretto gli errori di stile, è stato generato il Javadoc per il codice, in modo da avere una documentazione automatica e aggiornata. Inoltre, è stato creato un sito web tramite GitHub Pages per avere una documentazione più user-friendly e facilmente accessibile. 

Per fare ciò si è optato per l'utilizzo di una GitHub Action che, tramite condizioni come una push su determinati branch, genera automaticamente il Javadoc. Questa documentazione viene pubblicata su un branch `javadoc`, automaticamente creato, e tramite le impostazioni del repository, viene pubblicata su GitHub Pages, in modo da avere una documentazione sempre aggiornata e facilmente accessibile.

\includegraphics[width=12cm]{report/img/github_javadoc.jpg}\\[1.5cm]

La documentazione del componente middleware sarà sempre reperibile
all' indirizzo delle githubpages del progetto con il suffisso javadoc \\ come ad esempio \href{https://sofy24.github.io/MiddlewareMaraffa/javadoc/}{\underline{https://sofy24.github.io/MiddlewareMaraffa/javadoc/}}.

\begin{lstlisting}[language=Bash, caption={Configurazione della GitHub Action per il Javadoc}, label=list:javadoc_action]
name: Deploy Javadoc

on:
  push:
    branches: [main, "develop", "style-doc"]

jobs:
  publish:
    runs-on: ubuntu-22.04
    permissions:
      contents: write # if you have a protection rule on your repository, you'll need to give write permission to the workflow.
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Deploy JavaDoc
        uses: MathieuSoysal/Javadoc-publisher.yml@v2.5.0
        with:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          javadoc-source-folder: app/build/docs/javadoc
          javadoc-branch: javadoc
          java-version: 20
          target-folder: javadoc  # url will be https://<username>.github.io/<repo>/javadoc, This can be left as nothing to generate javadocs in the root folder.
          project: gradle
\end{lstlisting}



\section{Deployment}
è opzionale
\section{Containerization}

Data l'architettura del progetto in microservizi, usare Docker per creare un'immagine per ogni servizio è stata una scelta naturale. 
L'obiettivo finale è avere un sistema facilmente deployabile e scalabile, eseguibile velocemente in un ambiente generico, con uno stack di container Docker che racchiuda tutto il sistema.
Per fare ciò è stato necessario creare un Dockerfile per ogni servizio, in modo da poter creare un'immagine durante la fase di deploy della continuous integration.
\vspace{1cm}

La \textbf{strategia di containerizzazione} per tutte le immagini create è stata quella di utilizzare un'immagine base di Alpine, in modo da avere immagini leggere e veloci da scaricare. Per ridurre la dimensione delle immagini,
si è utilizzata un'immagine di sviluppo per compilare il codice e un'immagine di produzione per eseguire il codice compilato, copiando solo i file necessari.

\begin{figure}[H]
\caption{Comparazione tra le immagini multi-stage e le immagini tradizionali}
\centering
\includegraphics[width=12cm]{report/img/multi_stage.png}\\[4.5cm]
\end{figure}

\subsection{NodeJS}

I servizi UserManagementMaraffa e BusinessLogic sono stati containerizzati utilizzando un'immagine di Node.js. Nell'esempio sotto, si può notare la distinzione tra i diversi stage.
\vspace{1cm}

\begin{lstlisting}[language=Python, caption={Dockerfile delle immagini NodeJS}, label=list:dockerfile_nodejs]
FROM node:20-alpine as base
WORKDIR /app
COPY yarn.lock package.json /app/
RUN yarn install
COPY . /app
RUN yarn build

FROM node:20-alpine
WORKDIR /app    
COPY --from=base /app/package.json /app/package.json
COPY --from=base /app/node_modules /app/node_modules
COPY --from=base /app/dist /app/dist
EXPOSE 3000
CMD ["node","dist/main.js"]
\end{lstlisting}

\subsection{Java}

La containerizzazione del middleware ha richiesto alcuni passaggi aggiuntivi rispetto ai servizi in Node.js.
È stato necessario adottare immagini diverse per gli stage di build e produzione, quindi usare un'immagine di Gradle per la build, nella quale eseguire i comandi di Gradle, e un'immagine di 
OpenJDK per l'esecuzione del JAR prodotto dalla build.

Per la compilazione con Gradle, nonostante non sia una pratica corretta, è stato necessario mantenere nella repository il file gradle-wrapper.jar, in quanto non era possibile scaricarlo durante la build all'interno delle GitHub Actions.
La build non utilizza il classico comando di Gradle per generare il file .jar, ma un task personalizzato che si occupa di generare il fatJar del servizio, poiché le dipendenze non venivano gestite correttamente all'interno del normale file .jar.

\begin{lstlisting}[language=Java, caption={Task del fatJar da includere nel container}, label=list:gradle_fatJar]
tasks.register<Jar>("fatJar") {
    archiveBaseName.set("Middleware")
    manifest {
        attributes["Main-Class"] = "server.Main"
    }
    from(sourceSets.main.get().output)
    dependsOn(configurations.runtimeClasspath)
    from({ configurations.runtimeClasspath.get().filter { it.name.endsWith("jar") }.map { zipTree(it) } })
    dependsOn("compileJava")
    duplicatesStrategy = DuplicatesStrategy.EXCLUDE // Puoi utilizzare altre strategie come DuplicatesStrategy.WARN per avvisare ma non fermare la build
}
\end{lstlisting}

\subsection{Angular}

La containerizzazione del frontend ha richiesto l'utilizzo di un'immagine di Node.js per lo stage di build, mentre per l'esecuzione è stata utilizzata un'immagine di Nginx.
Nginx serve per eseguire l'applicazione all'interno del container e per poterla raggiungere dall'esterno. Per fare ciò è stato necessario configurare Nginx tramite un file di configurazione che ha permesso anche di gestire un'operazione di reverse proxy per indirizzare le chiamate al backend.

\begin{lstlisting}[language=Python, caption={Configurazione Nginx del front-end}, label=list:nginx_frontend]
server {
    listen 80;
    
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
        try_files $uri $uri/ /index.html;
    }

    location /api/ {
        proxy_pass "http://${API_HOST}:${API_PORT}/";
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
    }
}
\end{lstlisting}

L'indirizzo del backend è stato configurato tramite variabili d'ambiente, in modo da poterlo cambiare facilmente in base all'ambiente in cui si trova il container, e queste variabili vengono sostituite a seconda dell'ambiente di deploy in cui l'applicativo Angular viene eseguito.


\section{Lettura variabili d'ambiente}

Data la scelta di dockerizzare interamente i servizi, è stato necessario l'utilizzo di variabili d'ambiente. Questo ha permesso di creare un sistema di deploy molto flessibile, in cui è possibile cambiare l'indirizzo del servizio a cui connettersi semplicemente modificando il file di configurazione del Docker Compose. I servizi in NodeJS leggono il contenuto delle variabili d'ambiente tramite il modulo `process.env`, mentre i servizi in Java utilizzano `System.getenv`. Questi comportamenti sono corretti per lo sviluppo locale e per ambienti di produzione in cui le variabili d'ambiente sono settate correttamente.

Per quanto riguarda invece lo sviluppo in CI, è stato necessario creare un file `.env.example` che contenesse tutte le variabili d'ambiente necessarie al funzionamento del servizio, in modo da poterle settare correttamente nel CI/CD, soprattutto per la fase di testing, e metterlo sulla repository. È importante tenere a mente che non dovrebbero mai essere caricati dati sensibili su strumenti di controllo di versione. In questo caso, non ci sono database o account cloud eventualmente raggiungibili dall'esterno.

\section{Monitoraggio}

In un progetto composto da microservizi deployati con container, il monitoraggio è essenziale per garantire il corretto funzionamento e la performance ottimale del sistema. Per realizzare un monitoraggio efficace dei container, sono stati impiegati i container di Grafana, Prometheus e cAdvisor.
Si ringrazia il lavoro di \href{https://medium.com/@sohammohite/docker-container-monitoring-with-cadvisor-prometheus-and-grafana-using-docker-compose-b47ec78efbc}{\underline{Soham Mohite}} per la configurazione e l'integrazione di questi strumenti.

\includegraphics[width=14cm]{report/img/monitor_schema.jpg}\\[0.5cm]

\subsection{Grafana}

Grafana è uno strumento open-source per la visualizzazione e l'analisi delle metriche raccolte. Viene utilizzato per creare dashboard personalizzate che mostrano lo stato e le performance dei microservizi. Con Grafana, è possibile configurare alert che notificano immediatamente eventuali problemi nel sistema, permettendo una risposta rapida e mirata.

\subsection{Prometheus}

Prometheus è un sistema di monitoraggio e di allarme progettato per raccogliere e memorizzare metriche in serie temporali. È stato configurato per raccogliere metriche dai container dei microservizi e da cAdvisor. Prometheus esegue la raccolta dei dati a intervalli regolari e li memorizza in un database time-series, rendendoli disponibili per l'analisi e la visualizzazione in Grafana.

\subsection{cAdvisor}

cAdvisor (Container Advisor) è uno strumento che fornisce informazioni sulle risorse utilizzate dai container, come CPU, memoria, rete e disco. È stato integrato con Prometheus per raccogliere e esportare le metriche dei container. cAdvisor offre una visione dettagliata delle performance di ogni container, aiutando a identificare e risolvere problemi di utilizzo delle risorse.

\subsection{Integrazione e Configurazione}

L'integrazione di Grafana, Prometheus e cAdvisor ha permesso di creare un sistema di monitoraggio completo. I container di cAdvisor raccolgono le metriche di utilizzo delle risorse dai container dei microservizi e le esportano a Prometheus. Prometheus memorizza queste metriche e le rende disponibili per la visualizzazione in Grafana. Le dashboard di Grafana sono configurate per mostrare le metriche chiave e fornire un'analisi dettagliata dello stato del sistema.

La configurazione di questi strumenti è stata gestita tramite Docker Compose, permettendo una facile implementazione e scalabilità del sistema di monitoraggio. Le variabili d'ambiente e i file di configurazione sono stati impostati per garantire la corretta connessione e funzionamento dei container di monitoraggio.

\begin{lstlisting}[language=Python, caption={Esempio di configurazione Docker Compose}, label=list:docker_compose_monitoring]
 cadvisor:
    container_name: cadvisor
    image: gcr.io/cadvisor/cadvisor:latest
    ports:
      - "8080:8080"
    volumes:
      - "/:/rootfs"
      - "/var/run:/var/run"
      - "/sys:/sys"
      - "/var/lib/docker/:/var/lib/docker"
      - "/dev/disk/:/dev/disk"
    privileged: true
    devices:
      - "/dev/kmsg"

  prometheus:
    container_name: prometheus
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - "./prometheus.yml:/etc/prometheus/prometheus.yml"
    privileged: true
    depends_on:
      - cadvisor

  grafana:
    container_name: grafana
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - DS_PROMETHEUS=prometheus
    volumes:
      - "grafana-data:/var/lib/grafana"
      - "./datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml"
      - "./dashboard.json:/var/lib/grafana/dashboards/dashboard.json"
      - "./default.yaml:/etc/grafana/provisioning/dashboards/default.yaml"
    privileged: true
    depends_on:
      - prometheus
\end{lstlisting}

Con questa configurazione, il sistema di monitoraggio offre una visione completa delle performance e dello stato dei microservizi, permettendo di mantenere un'operatività ottimale e di intervenire prontamente in caso di anomalie.


\section{Docker-compose TODO}

Infine il risultato prodotto è stata un file docker-compose che raggruppa tutti i servizi in un unico stack, definendo le dipendenze tra i container e semplificando il deploy
è stato creato un network interno per poter permettere la comunicazione dei container tra di loro e particolari network invece per connettere i database ai servizi che ne fanno uso.
Sono state inserite anche delle dipendenze tra i servizi, ad esempio lo user service ha come vincolo che il container del database sia avviato prima di esso. 
\vspace{0.5cm}
Sono stati inseriti dei servizi che permettono di monitorare i database: 
\begin{itemize}
    \item \textbf{Adminer:} un'interfaccia web per la gestione dei database, che permette di visualizzare i dati, creare tabelle, eseguire query e molto altro.
    \item \textbf{Mongo Express:} un'interfaccia web per la gestione dei database MongoDB.
\end{itemize}

TODO quando potremo testare un po'meglio e essere sicuri che effettivamente funzioni

\section{Degna di nota la CI/CD per le relazioni}

Per lo sviluppo di questa, e di future relazioni, è stata creata una CI/CD. Questa è poi stata inclusa a sua volta in un template GitHub appositamente nato per lo sviluppo di nuove relazioni. Contiene una serie di documenti in LaTeX, che rappresentano uno scheletro per le relazioni, e la CI per poter pubblicare la relazione in continuous integration in formato HTML sulla piattaforma GitHub Pages e fornire una release contenente il PDF della relazione. L'utilizzo di GitHub rende lo sviluppo della relazione più semplice, non obbligando a scegliere strumenti come Overleaf come editor di testo, mantenendo la relazione versionata e permettendo di lavorare in parallelo con altri membri del team sfruttando tutte le comodità offerte da Git.

A questo \href{https://github.com/mega2799/Report-ghPages-latex}{\underline{link}} il template spiega alcuni dei passaggi per poterlo utilizzare. In alternativa, è stato inserito anche un file bash che permette, tramite un container Docker, di creare localmente il PDF della relazione utilizzando i software pandoc e latexmk.

Sono stati fondamentali i lavori di \href{https://github.com/MemerGamer/LaTex-Publishing}{\underline{Memer Gamer}} per la base del workflow delle pubblicazioni su GitHub Pages e \href{https://www.overleaf.com/latex/templates/university-of-reading-computer-science-report-template-and-guide/xhttddjhkwrf}{\underline{Varun Ojha}} per il template.


% We mentioned in Chapter~\ref{ch:into} %[example backward reference to a chapter or section.]
% that a project report's structure could follow a particular paradigm. Hence, the organization of a report (effectively the Table of Content of a report) can vary depending on the type of project you are doing. Check which of the given examples suit your project. Alternatively, follow your supervisor's advice.

% \section{Examples of the sections of a methodology chapter}
% A general report structure is summarised (suggested) in Table~\ref{tab:gen_template}. Table~\ref{tab:gen_template} describes that, in general, a typical report structure has three main parts: (1) front matter, (2) main text, and (3) end matter. %[\textbf{also notice that the preceding sentence is an example of a numbered list in a text body}]. 
% The structure of the front matter and end matter will remain the same for all the undergraduate final year project report. However, the main text varies as per the project's needs.
% \begin{table}[h!]
%     \centering
%     \caption{Undergraduate report template structure}
%     \label{tab:gen_template}
%     \begin{tabular}{llll}     
%         \toprule
%         \multirow{7}{3cm}{Frontmatter} 
%         & & Title Page & \\                  
%         & & Abstract &    \\          
%         & & Acknowledgements & \\                            
%         & & Table of Contents &    \\                                
%         & & List of Figures   &    \\                        
%         & & List of Tables    &    \\                
%         & & List of Abbreviations  &    \\                     
%         & &   &    \\                        
%         \multirow{7}{3cm}{Main text}
%         & Chapter 1 & Introduction   &    \\                         
%         & Chapter 2 & Literature Review   &    \\
%         & Chapter 3 & Methodology   &    \\
%         & Chapter 4 & Results    &    \\
%         & Chapter 5 & Discussion and Analysis  &    \\
%         & Chapter 6 & Conclusions and Future Work  &    \\        
%         & Chapter 7 & Refection  &    \\          
%         & &   &    \\                       
%         \multirow{2}{3cm}{End matter}
%         & & References  &    \\   
%         & & Appendices (Optional)  &    \\ 
%         & & Index (Optional)  &    \\ 
%         \bottomrule
%     \end{tabular}
% \end{table}

% \subsection{Example of a software/Web development main text structure}
% \label{subsec:se_chpters}
% Notice that the ``methodology'' Chapter of Software/Web development in Table~\ref{tab:soft_eng_temp} takes a standard software engineering paradigm (approach). Alternatively, these suggested sections can be the chapters of their own. Also, notice that ``Chapter 5'' in Table~\ref{tab:soft_eng_temp} is ``Testing and Validation'' which is different from the general report template mentioned in Table~\ref{tab:gen_template}. Check with your supervisor if in doubt.
% \begin{table}[h!]
%     \centering
%     \caption{Example of a software engineering-type report structure}
%     \label{tab:soft_eng_temp}
%     \begin{tabular}{lll}     
%         \toprule                   
%         Chapter 1 & Introduction   &    \\        
%         Chapter 2 & Literature Review  &    \\                   
%         Chapter 3 & Methodology   &    \\
%         &               & Requirements specifications   \\
%         &               & Analysis   \\
%         &               & Design   \\
%         &               & Implementations   \\
%         Chapter 4 & Testing and Validation  &    \\
%         Chapter 5 & Results and Discussion      &    \\
%         Chapter 6 & Conclusions and Future Work  &    \\        
%         Chapter 7 & Reflection  &    \\                          
%         \bottomrule
%     \end{tabular}
% \end{table}

% \subsection{Example of an algorithm analysis main text structure}
% Some project might involve the implementation of a state-of-the-art algorithm and its performance analysis and comparison with other algorithms. In that case, the suggestion in Table~\ref{tab:algo_temp} may suit you the best. 
% \begin{table}[h!]
%     \centering
%     \caption{Example of an algorithm analysis type report structure}
%     \label{tab:algo_temp}
%     \begin{tabular}{lll}     
%         \toprule                   
%         Chapter 1 & Introduction  &    \\        
%         Chapter 2 & Literature Review  &    \\                
%         Chapter 3 & Methodology   &    \\
%         &               & Algorithms descriptions  \\
%         &               & Implementations   \\
%         &               & Experiments design   \\
%         Chapter 4 & Results       &  \\
%         Chapter 5 & Discussion and Analysis  &    \\
%         Chapter 6 & Conclusion and Future Work  &    \\        
%         Chapter 7 & Reflection  &    \\          
%         \bottomrule
%     \end{tabular}
% \end{table}

% \subsection{Example of an application type main text structure}
% If you are applying some algorithms/tools/technologies on some problems/datasets/etc., you may use the methodology section prescribed in Table~\ref{tab:app_temp}.  
% \begin{table}[h!]
%     \centering
%     \caption{Example of an application type report structure}
%     \label{tab:app_temp}
%     \begin{tabular}{lll}     
%         \toprule                   
%         Chapter 1 & Introduction  &    \\        
%         Chapter 2 & Literature Review  &    \\                
%         Chapter 3 & Methodology   &    \\
%         &               & Problems (tasks) descriptions  \\
%         &               & Algorithms/tools/technologies/etc. descriptions  \\        
%         &               & Implementations   \\
%         &               & Experiments design and setup   \\
%         Chapter 4 & Results       &  \\
%         Chapter 5 & Discussion and Analysis  &    \\
%         Chapter 6 & Conclusion and Future Work  &    \\        
%         Chapter 7 & Reflection  &    \\          
%         \bottomrule
%     \end{tabular}
% \end{table}

% \subsection{Example of a science lab-type main text structure}
% If you are doing a science lab experiment type of project, you may use the  methodology section suggested in Table~\ref{tab:lab_temp}. In this kind of project, you may refer to the ``Methodology'' section as ``Materials and Methods.''
% \begin{table}[h!]
%     \centering
%     \caption{Example of a science lab experiment-type report structure}
%     \label{tab:lab_temp}
%     \begin{tabular}{lll}     
%         \toprule                   
%         Chapter 1 & Introduction  &    \\        
%         Chapter 2 & Literature Review  &    \\                
%         Chapter 3 & Materials and Methods   &    \\
%         &               & Problems (tasks) description  \\
%         &               & Materials \\        
%         &               & Procedures  \\                
%         &               & Implementations   \\
%         &               & Experiment set-up   \\
%         Chapter 4 & Results       &  \\
%         Chapter 5 & Discussion and Analysis  &    \\
%         Chapter 6 & Conclusion and Future Work  &    \\        
%         Chapter 7 & Reflection  &    \\          
%         \bottomrule
%     \end{tabular}
% \end{table}

% \section{Example of an Equation in \LaTeX}
% Eq.~\ref{eq:eq_example} [note that this is an example of an equation's in-text citation] is an example of an equation in \LaTeX. In Eq.~\eqref{eq:eq_example}, $ s $ is the mean of elements $ x_i \in \mathbf{x} $: 

% \begin{equation}
% \label{eq:eq_example} % label used to refer the eq in text
% s = \frac{1}{N} \sum_{i = 1}^{N} x_i. 
% \end{equation}

% Have you noticed that all the variables of the equation are defined using the \textbf{in-text} maths command \$.\$, and Eq.~\eqref{eq:eq_example} is treated as a part of the sentence with proper punctuation? Always treat an equation or expression as a part of the sentence. 

% \section{Example of a Figure in \LaTeX}
% Figure~\ref{fig:chart_a} is an example of a figure in \LaTeX. For more details, check the link:

% \href{https://en.wikibooks.org/wiki/LaTeX/Floats,_Figures_and_Captions}{wikibooks.org/wiki/LaTeX/Floats,\_Figures\_and\_Captions}.

% \noindent
% Keep your artwork (graphics, figures, illustrations) clean and readable. At least 300dpi is a good resolution of a PNG format artwork. However, an SVG format artwork saved as a PDF will produce the best quality graphics. There are numerous tools out there that can produce vector graphics and let you save that as an SVG file and/or as a PDF file. One example of such a tool is the ``Flow algorithm software''. Here is the link for that: \href{http://www.flowgorithm.org/download/}{flowgorithm.org}.
% \begin{figure}[ht]
%     \centering
%     % \includegraphics[scale=0.3]{figures/chart.pdf}
%     \caption{Example figure in \LaTeX.}
%     \label{fig:chart_a}
% \end{figure}

% \clearpage %  use command \clearpage when you want section or text to appear in the next page.

% \section{Example of an algorithm in \LaTeX}
% Algorithm~\ref{algo:algo_example} is a good example of an algorithm in \LaTeX.  
% \begin{algorithm}
%     \caption{Example caption: sum of all even numbers}
%     \label{algo:algo_example}
%     \begin{algorithmic}[1]
%         \Require{$ \mathbf{x}  = x_1, x_2, \ldots, x_N$}
%         \Ensure{$EvenSum$ (Sum of even numbers in $ \mathbf{x} $)}
%         \Statex
%         \Function{EvenSummation}{$\mathbf{x}$}
%         \State {$EvenSum$ $\gets$ {$0$}}
%         \State {$N$ $\gets$ {$length(\mathbf{x})$}}
%         \For{$i \gets 1$ to $N$}                    
%         \If{$ x_i\mod 2 == 0$}  \Comment check if a number is even?
%         \State {$EvenSum$ $\gets$ {$EvenSum + x_i$}}
%         \EndIf
%         \EndFor
%         \State \Return {$EvenSum$}
%         \EndFunction
%     \end{algorithmic}
% \end{algorithm}
 
% \section{Example of code snippet  in \LaTeX}

% Code Listing~\ref{list:python_code_ex} is a good example of including a code snippet in a report. While using code snippets, take care of the following:
% \begin{itemize}
%     \item do not paste your entire code (implementation) or everything you have coded. Add code snippets only. 
%     \item The algorithm shown in Algorithm~\ref{algo:algo_example} is usually preferred over code snippets in a technical/scientific report. 
%     \item Make sure the entire code snippet or algorithm stays on a single page and does not overflow to another page(s).  
% \end{itemize}

% Here are three examples of code snippets for three different languages (Python, Java, and CPP) illustrated in Listings~\ref{list:python_code_ex}, \ref{list:java_code_ex}, and \ref{list:cpp_code_ex} respectively.  

% \begin{lstlisting}[language=Python, caption={Code snippet in \LaTeX ~and  this is a Python code example}, label=list:python_code_ex]
% import numpy as np

% x  = [0, 1, 2, 3, 4, 5] # assign values to an array
% evenSum = evenSummation(x) # call a function

% def evenSummation(x):
%     evenSum = 0
%     n = len(x)
%     for i in range(n):
%         if np.mod(x[i],2) == 0: # check if a number is even?
%             evenSum = evenSum + x[i]
%     return evenSum
% \end{lstlisting}

% Here we used  the ``\textbackslash clearpage'' command and forced-out the second listing example onto the next page. 
% \clearpage  %
% \begin{lstlisting}[language=Java, caption={Code snippet in \LaTeX ~and  this is a Java code example}, label=list:java_code_ex]
% public class EvenSum{ 
%     public static int evenSummation(int[] x){
%         int evenSum = 0;
%         int n = x.length;
%         for(int i = 0; i < n; i++){
%             if(x[i]%2 == 0){ // check if a number is even?
%                 evenSum = evenSum + x[i];
%             }
%         }
%         return evenSum;     
%     }
%     public static void main(String[] args){ 
%         int[] x  = {0, 1, 2, 3, 4, 5}; // assign values to an array
%         int evenSum = evenSummation(x);
%         System.out.println(evenSum);
%     } 
% } 
% \end{lstlisting}


% \begin{lstlisting}[language=C, caption={Code snippet in \LaTeX ~and  this is a C/C++ code example}, label=list:cpp_code_ex]
% int evenSummation(int x[]){
%     int evenSum = 0;
%     int n = sizeof(x);
%     for(int i = 0; i < n; i++){
%         if(x[i]%2 == 0){ // check if a number is even?
%             evenSum = evenSum + x[i];
%     	}
%     }
%     return evenSum;     
% }

% int main(){
%     int x[]  = {0, 1, 2, 3, 4, 5}; // assign values to an array
%     int evenSum = evenSummation(x);
%     cout<<evenSum;
%     return 0;
% }
% \end{lstlisting}



% \section{Example of in-text citation style}
% \subsection{Example of the equations and illustrations placement and reference in the text}
% Make sure whenever you refer to the equations, tables, figures, algorithms,  and listings for the first time, they also appear (placed) somewhere on the same page or in the following page(s). Always make sure to refer to the equations, tables and figures used in the report. Do not leave them without an \textbf{in-text citation}. You can refer to equations, tables and figures more them once.

% \subsection{Example of the equations and illustrations style}
% Write \textbf{Eq.} with an uppercase ``Eq`` for an equation before using an equation number with (\textbackslash eqref\{.\}). Use ``Table'' to refer to a table, ``Figure'' to refer to a figure, ``Algorithm'' to refer to an algorithm and ``Listing'' to refer to listings (code snippets). Note that, we do not use the articles ``a,'' ``an,'' and ``the'' before the words Eq., Figure, Table, and Listing, but you may use an article for referring the words figure, table, etc. in general.

% For example, the sentence ``A report structure is shown in \textbf{the} Table~\ref{tab:gen_template}'' should be written as ``A report structure is shown \textbf{in} Table~\ref{tab:gen_template}.'' 
 

% \section{Summary}
% Write a summary of this chapter.

% ~\\[5em]
% \noindent
% {\huge\textbf{Note:}} In the case of \textbf{software engineering} project a Chapter ``\textbf{Testing and Validation}'' should precede the ``Results'' chapter. See Section~\ref{subsec:se_chpters} for report organization of such project. 

